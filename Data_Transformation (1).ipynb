{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cN2obkO0QCM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "\n",
        "df = pd.read_csv('animal_data.csv')\n",
        "\n",
        "animal_name_mapping = {\n",
        "    'dogs': 'Dog',\n",
        "    'cattle': 'Cattle',\n",
        "    'cats': 'Cat',\n",
        "    'horses': 'Horse',\n",
        "    'sheep': 'Sheep',\n",
        "    'goats': 'Goat',\n",
        "    'pigs': 'Pig',\n",
        "    'chickens': 'Chicken',\n",
        "    'rabbits': 'Rabbit',\n",
        "    'ducks': 'Duck',\n",
        "    'geese': 'Goose',\n",
        "    'mice': 'Mouse',\n",
        "    'rats': 'Rat'}\n",
        "\n",
        "def standardize_animal_name(name):\n",
        "    name = name.strip()\n",
        "\n",
        "    name_lower = name.lower()\n",
        "    for key, value in animal_name_mapping.items():\n",
        "        if name_lower == key:\n",
        "            return value\n",
        "\n",
        "    if name_lower.endswith('s') and not name_lower in ['species']:\n",
        "        singular = name[:-1]\n",
        "        if singular.lower() in [k.lower() for k in animal_name_mapping.values()]:\n",
        "            for value in animal_name_mapping.values():\n",
        "                if singular.lower() == value.lower():\n",
        "                    return value\n",
        "        return name.title()\n",
        "\n",
        "df['AnimalName'] = df['AnimalName'].apply(standardize_animal_name)\n",
        "symptom_columns = ['symptoms1', 'symptoms2', 'symptoms3', 'symptoms4', 'symptoms5']\n",
        "\n",
        "# Dictionary for common symptom spelling corrections\n",
        "symptom_corrections = {\n",
        "    'abnomalities': 'Abnormalities',\n",
        "    'Abnormalalities': 'Abnormalities',\n",
        "    'vommitting': 'Vomiting',\n",
        "    'vomitting': 'Vomiting',\n",
        "    'Aneamia': 'Anaemia',\n",
        "    'Anemia': 'Anaemia',\n",
        "    'Anoxeria': 'Anorexia',\n",
        "    'Attacks': 'Attack',\n",
        "    'diarhea': 'Diarrhea',\n",
        "    'diarrhoea': 'Diarrhea',\n",
        "    'Dull ness': 'Dullness',\n",
        "    'Dull': 'Dullness',\n",
        "    'Gasc': 'Gas',\n",
        "    'Inappentence': 'Inappetence',\n",
        "    'weekness': 'Weakness',\n",
        "    'lethargy': 'Lethargy',\n",
        "    'lethargic': 'Lethargy',\n",
        "    'seizuers': 'Seizures',\n",
        "    'seizuer': 'Seizures',\n",
        "    'painfull': 'Painful'\n",
        "}\n",
        "\n",
        "def standardize_symptom(symptom):\n",
        "    if pd.isna(symptom) or symptom == \"None reported\":\n",
        "        return symptom\n",
        "    symptom = symptom.strip()\n",
        "    symptom_lower = symptom.lower()\n",
        "    for key, value in symptom_corrections.items():\n",
        "        if symptom_lower == key.lower():\n",
        "            return value\n",
        "\n",
        "    return symptom.capitalize()\n",
        "\n",
        "for col in symptom_columns:\n",
        "    df[col] = df[col].apply(standardize_symptom)\n",
        "\n",
        "# Create an unpivoted version for easier analysis\n",
        "unpivoted_data = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    for col in symptom_columns:\n",
        "        if pd.notna(row[col]) and row[col] != \"None reported\":\n",
        "            unpivoted_data.append({\n",
        "                'AnimalName': row['AnimalName'],\n",
        "                'Symptom': row[col],\n",
        "                'Dangerous': row['Dangerous']\n",
        "            })\n",
        "\n",
        "unpivoted_df = pd.DataFrame(unpivoted_data)\n",
        "\n",
        "# Features for Question 1: Symptom frequency and danger correlation\n",
        "def create_symptom_frequency_features(df, unpivoted_df):\n",
        "    # Symptom frequency by species\n",
        "    symptom_by_species = unpivoted_df.groupby(['AnimalName', 'Symptom']).size().reset_index(name='Count')\n",
        "\n",
        "    # Get total counts per species for percentages\n",
        "    species_counts = unpivoted_df['AnimalName'].value_counts().reset_index()\n",
        "    species_counts.columns = ['AnimalName', 'TotalSymptoms']\n",
        "\n",
        "    # Merge to calculate percentages\n",
        "    symptom_by_species = pd.merge(symptom_by_species, species_counts, on='AnimalName')\n",
        "    symptom_by_species['Percentage'] = symptom_by_species['Count'] / symptom_by_species['TotalSymptoms']\n",
        "\n",
        "    # Symptom danger correlation\n",
        "    danger_correlation = unpivoted_df.groupby('Symptom')['Dangerous'].apply(\n",
        "        lambda x: (x == 'Yes').mean()).reset_index()\n",
        "    danger_correlation.columns = ['Symptom', 'DangerCorrelation']\n",
        "\n",
        "    # Overall danger rate for comparison\n",
        "    overall_danger_rate = (unpivoted_df['Dangerous'] == 'Yes').mean()\n",
        "\n",
        "    # Calculate danger coefficient (how much more likely danger is with this symptom)\n",
        "    danger_correlation['DangerCoefficient'] = danger_correlation['DangerCorrelation'] / overall_danger_rate\n",
        "\n",
        "    return symptom_by_species, danger_correlation\n",
        "\n",
        "# Features for Question 2: Species prone to dangerous conditions\n",
        "def create_species_risk_features(df):\n",
        "    # Species danger rate\n",
        "    species_danger = df.groupby('AnimalName')['Dangerous'].apply(\n",
        "        lambda x: (x == 'Yes').mean()\n",
        "    ).reset_index()\n",
        "    species_danger.columns = ['AnimalName', 'DangerRate']\n",
        "\n",
        "    # Count cases for confidence calculation\n",
        "    species_counts = df['AnimalName'].value_counts().reset_index()\n",
        "    species_counts.columns = ['AnimalName', 'TotalCases']\n",
        "\n",
        "    # Merge to get counts\n",
        "    species_danger = pd.merge(species_danger, species_counts, on='AnimalName')\n",
        "\n",
        "    # Calculate 95% confidence interval for danger rate\n",
        "    # Using normal approximation to binomial (valid for large enough samples)\n",
        "    species_danger['CI_Lower'] = species_danger.apply(\n",
        "        lambda x: max(0, x['DangerRate'] - 1.96 * np.sqrt((x['DangerRate'] * (1 - x['DangerRate'])) / x['TotalCases'])),\n",
        "        axis=1\n",
        "    )\n",
        "    species_danger['CI_Upper'] = species_danger.apply(\n",
        "        lambda x: min(1, x['DangerRate'] + 1.96 * np.sqrt((x['DangerRate'] * (1 - x['DangerRate'])) / x['TotalCases'])),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Calculate symptom count distribution\n",
        "    # First, count non-NA symptoms per row\n",
        "    df['SymptomCount'] = df[['symptoms1', 'symptoms2', 'symptoms3', 'symptoms4', 'symptoms5']].apply(\n",
        "        lambda x: sum(1 for item in x if pd.notna(item) and item != \"None reported\"),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Symptom count stats by species\n",
        "    symptom_count_stats = df.groupby('AnimalName')['SymptomCount'].agg(['mean', 'median', 'min', 'max']).reset_index()\n",
        "\n",
        "    # Correlation between symptom count and danger by species\n",
        "    symptom_danger_corr = []\n",
        "    for animal in df['AnimalName'].unique():\n",
        "        animal_df = df[df['AnimalName'] == animal]\n",
        "        if len(animal_df) > 5:  # Only calculate if we have enough samples\n",
        "            danger_numeric = (animal_df['Dangerous'] == 'Yes').astype(int)\n",
        "            correlation = np.corrcoef(animal_df['SymptomCount'], danger_numeric)[0, 1]\n",
        "            symptom_danger_corr.append({\n",
        "                'AnimalName': animal,\n",
        "                'Correlation': correlation\n",
        "            })\n",
        "\n",
        "    symptom_danger_corr_df = pd.DataFrame(symptom_danger_corr)\n",
        "\n",
        "    return species_danger, symptom_count_stats, symptom_danger_corr_df\n",
        "\n",
        "# Features for Question 3: Symptom combinations and danger likelihood\n",
        "def create_symptom_combination_features(df):\n",
        "    # Create combinations of symptoms\n",
        "    symptom_combinations = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        symptoms = [row[f'symptoms{i}'] for i in range(1, 6)\n",
        "                   if pd.notna(row[f'symptoms{i}']) and row[f'symptoms{i}'] != \"None reported\"]\n",
        "\n",
        "        # Record individual symptoms\n",
        "        for symptom in symptoms:\n",
        "            symptom_combinations.append({\n",
        "                'AnimalName': row['AnimalName'],\n",
        "                'Combination': symptom,\n",
        "                'CombinationType': 'Single',\n",
        "                'Dangerous': row['Dangerous']\n",
        "            })\n",
        "\n",
        "        # Generate pairs of symptoms\n",
        "        if len(symptoms) >= 2:\n",
        "            for i in range(len(symptoms)):\n",
        "                for j in range(i+1, len(symptoms)):\n",
        "                    pair = f\"{symptoms[i]} + {symptoms[j]}\"\n",
        "                    symptom_combinations.append({\n",
        "                        'AnimalName': row['AnimalName'],\n",
        "                        'Combination': pair,\n",
        "                        'CombinationType': 'Pair',\n",
        "                        'Dangerous': row['Dangerous']\n",
        "                    })\n",
        "\n",
        "        # Generate triplets of symptoms\n",
        "        if len(symptoms) >= 3:\n",
        "            for i in range(len(symptoms)):\n",
        "                for j in range(i+1, len(symptoms)):\n",
        "                    for k in range(j+1, len(symptoms)):\n",
        "                        triplet = f\"{symptoms[i]} + {symptoms[j]} + {symptoms[k]}\"\n",
        "                        symptom_combinations.append({\n",
        "                            'AnimalName': row['AnimalName'],\n",
        "                            'Combination': triplet,\n",
        "                            'CombinationType': 'Triplet',\n",
        "                            'Dangerous': row['Dangerous']\n",
        "                        })\n",
        "\n",
        "    # Create DataFrame from the combinations\n",
        "    combinations_df = pd.DataFrame(symptom_combinations)\n",
        "\n",
        "    # Calculate danger rate for each combination\n",
        "    combination_stats = combinations_df.groupby(['Combination', 'CombinationType']).agg(\n",
        "        Count=('Dangerous', 'count'),\n",
        "        DangerousCount=('Dangerous', lambda x: (x == 'Yes').sum())\n",
        "    ).reset_index()\n",
        "\n",
        "    combination_stats['DangerRate'] = combination_stats['DangerousCount'] / combination_stats['Count']\n",
        "    combination_stats = combination_stats[combination_stats['Count'] >= 3]\n",
        "    combination_stats = combination_stats.sort_values(['DangerRate', 'Count'], ascending=[False, False])\n",
        "\n",
        "    return combinations_df, combination_stats\n",
        "\n",
        "# Features for Question 4: Species-specific patterns\n",
        "def create_species_pattern_features(df, unpivoted_df):\n",
        "    # Species-specific symptoms (distinctiveness score)\n",
        "    # Calculate the proportion of each symptom within a species\n",
        "    symptom_species_prop = unpivoted_df.groupby(['AnimalName', 'Symptom']).size().reset_index(name='Count')\n",
        "\n",
        "    # Get total for each species\n",
        "    species_totals = symptom_species_prop.groupby('AnimalName')['Count'].sum().reset_index()\n",
        "    species_totals.columns = ['AnimalName', 'TotalSymptoms']\n",
        "\n",
        "    # Calculate proportion within species\n",
        "    symptom_species_prop = pd.merge(symptom_species_prop, species_totals, on='AnimalName')\n",
        "    symptom_species_prop['PropWithinSpecies'] = symptom_species_prop['Count'] / symptom_species_prop['TotalSymptoms']\n",
        "\n",
        "    # Calculate the overall proportion of this symptom across all species\n",
        "    symptom_totals = symptom_species_prop.groupby('Symptom')['Count'].sum().reset_index()\n",
        "    total_symptoms = symptom_species_prop['Count'].sum()\n",
        "    symptom_totals['OverallProportion'] = symptom_totals['Count'] / total_symptoms\n",
        "\n",
        "    # Merge back to calculate distinctiveness\n",
        "    symptom_species_prop = pd.merge(symptom_species_prop, symptom_totals[['Symptom', 'OverallProportion']], on='Symptom')\n",
        "\n",
        "    # Distinctiveness score: how much more common this symptom is in this species vs overall\n",
        "    symptom_species_prop['Distinctiveness'] = symptom_species_prop['PropWithinSpecies'] / symptom_species_prop['OverallProportion']\n",
        "\n",
        "    # Species-specific danger patterns\n",
        "    # For each species, which symptoms correlate most with danger\n",
        "    species_danger_patterns = []\n",
        "\n",
        "    for animal in unpivoted_df['AnimalName'].unique():\n",
        "        animal_data = unpivoted_df[unpivoted_df['AnimalName'] == animal]\n",
        "\n",
        "        # Only proceed if we have enough data for this species\n",
        "        if len(animal_data) < 10:\n",
        "            continue\n",
        "\n",
        "        # For each symptom in this species, calculate danger correlation\n",
        "        for symptom in animal_data['Symptom'].unique():\n",
        "            symptom_data = animal_data[animal_data['Symptom'] == symptom]\n",
        "            if len(symptom_data) < 5:  # Skip if too few instances\n",
        "                continue\n",
        "\n",
        "            danger_rate = (symptom_data['Dangerous'] == 'Yes').mean()\n",
        "            species_danger_patterns.append({\n",
        "                'AnimalName': animal,\n",
        "                'Symptom': symptom,\n",
        "                'SymptomCount': len(symptom_data),\n",
        "                'DangerRate': danger_rate\n",
        "            })\n",
        "\n",
        "    species_danger_patterns_df = pd.DataFrame(species_danger_patterns)\n",
        "\n",
        "    # Calculate overall danger rate for each species for comparison\n",
        "    species_overall_danger = unpivoted_df.groupby('AnimalName')['Dangerous'].apply(\n",
        "        lambda x: (x == 'Yes').mean()\n",
        "    ).reset_index()\n",
        "    species_overall_danger.columns = ['AnimalName', 'OverallDangerRate']\n",
        "\n",
        "    # Merge to calculate relative risk\n",
        "    species_danger_patterns_df = pd.merge(species_danger_patterns_df,\n",
        "                                         species_overall_danger,\n",
        "                                         on='AnimalName')\n",
        "\n",
        "    # Relative risk: how much more/less dangerous this symptom is compared to species average\n",
        "    species_danger_patterns_df['RelativeRisk'] = species_danger_patterns_df['DangerRate'] / species_danger_patterns_df['OverallDangerRate']\n",
        "\n",
        "    # Sort to find most predictive symptoms for each species\n",
        "    species_danger_patterns_df = species_danger_patterns_df.sort_values(['AnimalName', 'RelativeRisk'], ascending=[True, False])\n",
        "\n",
        "    return symptom_species_prop, species_danger_patterns_df\n",
        "\n",
        "# Run all the feature creation functions\n",
        "symptom_by_species, danger_correlation = create_symptom_frequency_features(df, unpivoted_df)\n",
        "species_danger, symptom_count_stats, symptom_danger_corr_df = create_species_risk_features(df)\n",
        "combinations_df, combination_stats = create_symptom_combination_features(df)\n",
        "symptom_species_prop, species_danger_patterns_df = create_species_pattern_features(df, unpivoted_df)\n",
        "\n",
        "symptom_by_species.to_csv('symptom_by_species.csv', index=False)\n",
        "danger_correlation.to_csv('symptom_danger_correlation.csv', index=False)\n",
        "species_danger.to_csv('species_danger_rates.csv', index=False)\n",
        "symptom_count_stats.to_csv('symptom_count_by_species.csv', index=False)\n",
        "symptom_danger_corr_df.to_csv('symptom_count_danger_correlation.csv', index=False)\n",
        "combination_stats.to_csv('symptom_combination_analysis.csv', index=False)\n",
        "symptom_species_prop.to_csv('species_specific_symptoms.csv', index=False)\n",
        "species_danger_patterns_df.to_csv('species_danger_patterns.csv', index=False)"
      ]
    }
  ]
}